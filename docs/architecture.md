# ğŸ— ArchitekturÃ¼bersicht â€“ Sprachassistent

Diese Datei beschreibt die Systemarchitektur des dezentralen Sprachassistenten, der auf Raspberry Pi, Odroid und einem zentralen Server basiert.

---

## ğŸ¯ Ziel

Ein verteilter Sprachassistent, der lokal Sprache versteht (STT), antwortet (TTS) und komplexe Aufgaben an eine zentrale Automatisierungslogik weiterleitet (n8n, Flowise, lokale LLMs).

---

## ğŸ§± Komponenten

### ğŸ”Š Raspi 4 (8 GB)

* **STT**: [`faster-whisper`](https://github.com/guillaumekln/faster-whisper)
* **TTS**: [`piper`](https://github.com/rhasspy/piper)
* **Intent-Routing**: Leitet einfache und komplexe Anfragen weiter
* **WebSocket-Server**: `ws-server.py` nimmt Spracheingaben entgegen

### ğŸ§° Raspi 400 (4 GB)

* **GUI**: Electron-/Web-basierte Steuerung Ã¼ber integrierte Tastatur + Display
* **WebSocket-Client**: sendet Sprache an Raspi 4, empfÃ¤ngt Antwort (Text + Audio)

### ğŸ§  Odroid N2

* **Flowise (Docker/NPM)**: Agent-basierte LLM-Antwortlogik
* **n8n (Docker/NPM)**: Automatisierungslogik fÃ¼r Smart-Home, Skills etc.

### â˜ï¸ Optionaler Server

* **lokale LLMs**: z.â€¯B. GGUF/OpenLLM/LLama.cpp
* **zentrale Flowise-/n8n-Instanzen**

---

## ğŸ”€ DatenflÃ¼sse

```mermaid
flowchart LR
  Raspi400 -->|Spracheingabe (Mic)| Raspi4
  Raspi4 -->|Transkript (Text)| Odroid
  Odroid -->|Antwort / Workflow| Raspi4
  Raspi4 -->|Sprachausgabe| Raspi400
```

---

## ğŸ” Netzwerk & Sicherheit

* **Tailscale VPN** verbindet alle GerÃ¤te sicher
* Token-Auth + IP-Filterung im WS-Server
* Optional: HTTPS mit lokalen Zertifikaten

---

## ğŸ§© Erweiterbarkeit

* Plugin-System fÃ¼r Skills
* Weitere GUIs (Mobile, Web)
* Mehrere STT/TTS-Knoten

---

## ğŸ“¦ Projektstruktur (Auszug)

```
cli.sh
config/
docs/
scripts/
ws-server/
voice-assistant-apps/
```

---

## ğŸ“Œ NÃ¤chste Schritte

* Skill-System dokumentieren (`docs/skill-system.md`)
* Netzwerk-Setup in `docs/tailscale-setup.md`
* Routing-Logik in `docs/routing.md`

