# üßë‚Äçüíª Codex Developer Prompt ‚Äî Refactor & Advance the Voice Assistant

**Mission:** Implement the refactoring plan in **small, verifiable sprints** without losing existing features (unless explicitly superseded). Keep latency low, quality high, and the repo clean (no duplicates, no dead code on the import path).

**Repository assumptions**

* Root contains `backend/`, `ws_server/`, `voice-assistant-apps/`, `gui/`, `archive/`, `tests/` or `testsuite/`.
* Current unified entrypoint is `ws_server/cli.py` (WebSocket) and a legacy `backend/ws-server/ws-server.py` still exists.
* Electron desktop app lives in `voice-assistant-apps/desktop`.

**Golden rules**

1. **No feature regressions.** Replace only when the new path fully covers the old behavior.
2. **Single source of truth.** One server entrypoint (`python -m ws_server.cli`). No mirror copies under `backend/ws-server/`.
3. **Idempotent changes.** Scripts and transforms can run repeatedly.
4. **Atomic PRs.** One sprint ‚Üí one commit with a clear message and a short changelog.
5. **Tests first mindset.** Add/adjust tests alongside changes. Keep them fast and hermetic.
6. **Naming hygiene.** Use clear, descriptive names. Avoid `enhanced/advanced/pro/v2/ultimate`.
7. **Local only.** Do not call external services or invent APIs. Operate on the repo as it is.

---

## Kickoff (run first)

```bash
git checkout -b feat/refactor-foundation
python3 -m pip install -U pip
# if ruff/pytest/pytest-asyncio not present:
python3 -m pip install ruff pytest pytest-asyncio
```

Create a **refactor dashboard** file to track progress:

* `DEPRECATIONS.md` ‚Äì list of files replaced/removed + new path.
* `docs/UNIFIED_SERVER.md` ‚Äì how to run, protocol, env, health/metrics.
* `docs/REFACTOR_PLAN.md` ‚Äì checklist of sprints below, keep in sync.

---

## Sprint 1 ‚Äî Duplicate detection & quarantine

**Goal:** Identify and quarantine parallel implementations and backups so they **cannot** be imported inadvertently.

**Tasks**

* Add `scripts/repo_hygiene.py` to detect:

  * backup files: `*.bak*`, `*indentfix*`, `*fix*`
  * parallel servers: `backend/ws-server/ws-server.py`, `ws_server/transport/*enhanced*`, legacy copies in `archive/`
  * duplicated TTS engines (e.g., Zonos in multiple places)
* Move legacy/unused to `archive/` and add `pyproject.toml`/`setup.cfg` `exclude` patterns or runtime guards so **none** are on `sys.path`.
* Add a CI‚Äëstyle check: `python scripts/repo_hygiene.py --check` exits non‚Äëzero on violations.

**Acceptance**

* `repo_hygiene` finds 0 violations.
* `DEPRECATIONS.md` lists every quarantined path and the replacement.

**Commit message**

```
sprint-1(repo-hygiene): detect duplicates, quarantine legacy code, add DEPRECATIONS.md
```

---

## Sprint 2 ‚Äî Single entrypoint & import path sanitation

**Goal:** One server entrypoint: `python -m ws_server.cli`. Desktop app must use this.

**Tasks**

* Ensure `voice-assistant-apps/desktop` spawns `python -m ws_server.cli` (not `backend/ws-server/ws-server.py`).
* In `ws_server/transport/server.py` add a **strict path gate** to prevent importing from `backend/ws-server/` unless explicitly needed for compatibility shims.
* Remove any dynamic legacy imports from hot paths; keep a minimal shim only if necessary and document in `DEPRECATIONS.md`.

**Acceptance**

* Desktop `npm start` logs show `ws_server.cli` entrypoint.
* No imports from `backend/ws-server/` at runtime.

**Commit message**

```
sprint-2(entrypoint): unify to ws_server.cli and harden import paths for legacy-free runtime
```

---

## Sprint 3 ‚Äî Modular slicing of the monolith

**Goal:** Break legacy server logic into cohesive modules without behavior change.

**Tasks**

* Create (or complete) target layout under `ws_server/`:

  ```
  core/      (config, connections, streams)
  protocol/  (json_v1, binary_v2, handshake)
  transport/ (server, fastapi_adapter)
  metrics/   (collector, http_api, perf_monitor)
  tts/       (manager, engines/{piper,kokoro,zonos})
  routing/   (intent_router, skills loader)
  auth/      (token, rate_limit placeholder)
  ```
* Extract code into modules with same public interfaces used by `cli.py` / current handlers.

**Acceptance**

* `python -m ws_server.cli` runs with identical logs and behavior as before.

**Commit message**

```
sprint-3(modularity): extract server monolith into core/protocol/transport/metrics/routing/tts/auth
```

---

## Sprint 4 ‚Äî Config consolidation & naming hygiene

**Goal:** One config source, consistent env usage, no magic literals.

**Tasks**

* `ws_server/core/config.py`: dataclass or pydantic settings loading `.env` + defaults.
* Replace scattered env reads with `Config`.
* Normalize names: `WS_HOST`, `WS_PORT`, `METRICS_PORT`, `STT_MODEL`, `STT_DEVICE`, `TTS_ENGINE`, `TTS_VOICE`, `JWT_SECRET`, etc.
* Remove suffixes in code identifiers; keep protocol names stable via `protocol/*`.

**Acceptance**

* `grep` shows no ad‚Äëhoc `os.getenv(...)` in non‚Äëconfig files.
* Docs updated with env table.

**Commit message**

```
sprint-4(config): centralize settings, normalize env names, update docs
```

---

## Sprint 5 ‚Äî TTS single source of truth & lazy loading

**Goal:** Only one Zonos/Piper/Kokoro implementation; engines are lazy‚Äëloaded, with graceful fallback.

**Tasks**

* Re‚Äëexport duplicates to a single canonical engine implementation (prefer `backend/tts/engine_zonos.py` or `ws_server/tts/engines/zonos.py` ‚Üí pick one; the other becomes a thin re‚Äëexport or is removed).
* `TTSManager` supports lazy import; if engine unavailable, mark **unavailable** and auto‚Äëfallback (Piper).

**Acceptance**

* When Zonos assets are missing, a warning is logged; Piper answers and system does not crash.

**Commit message**

```
sprint-5(tts): unify engine sources, add lazy loading and robust fallback
```

---

## Sprint 6 ‚Äî STT in‚Äëmemory & streaming‚Äëfriendly

**Goal:** No temp files; ready for streaming STT.

**Tasks**

* Convert STT ingestion to in‚Äëmemory buffers (`bytes` ‚Üí `np.int16`), remove WAV temp files and subprocesses.
* Keep current behavior and quality; add TODO stubs for true streaming.

**Acceptance**

* No file I/O in STT hot path; latency drops measurably on short utterances.

**Commit message**

```
sprint-6(stt): eliminate temp-file I/O; in-memory audio path for faster transcription
```

---

## Sprint 7 ‚Äî Binary ingress + JSON compatibility

**Goal:** Unified transport that accepts JSON v1 and binary audio frames, negotiated in handshake.

**Tasks**

* `protocol/handshake.py`: accept `{"op":"hello"}` and legacy `{"type":"hello"}`; reply `{"op":"ready", "features": {...}}`.
* `protocol/binary_v2.py`: parser/builder for audio frames; route to STT pipeline.
* Keep JSON `audio_chunk` (Base64) as fallback.

**Acceptance**

* Integration test: JSON‚Äëonly client works; binary client streams PCM16 LE frames.

**Commit message**

```
sprint-7(protocol): handshake negotiation; add binary audio ingress alongside JSON v1
```

---

## Sprint 8 ‚Äî Staged TTS UX (intro Piper, main Zonos)

**Goal:** Perceptibly lower TTFB with high‚Äëquality follow‚Äëup.

**Tasks**

* `_limit_and_chunk(text)` (‚â§500 chars; target 80‚Äì180 per chunk).
* `_tts_staged()`:

  * Stage A: short Piper intro (CPU) first.
  * Stage B: Zonos main chunks (GPU) in parallel; cap chunks (‚â§3) and per‚Äëchunk timeout (e.g., 8‚Äì10s).
* New WS messages: `tts_chunk` and `tts_sequence_end`.

**Acceptance**

* Desktop client receives intro chunk within \~sub‚Äësecond, then main chunks; on Zonos timeout only intro is played and sequence ends.

**Commit message**

```
sprint-8(tts-staged): chunking + staged playback (Piper intro ‚Üí Zonos main) with timeouts and sequence events
```

---

## Sprint 9 ‚Äî Metrics unification

**Goal:** One metrics collector for connections, audio throughput, TTS/STT latencies, errors.

**Tasks**

* `metrics/collector.py`: counters, histograms (e.g., `tts_chunk_emitted_total`, `tts_sequence_timeout_total`, `stt_latency_ms`).
* `metrics/http_api.py`: `/metrics`, `/health`.

**Acceptance**

* `curl http://127.0.0.1:$METRICS_PORT/metrics` exposes new metrics; `/health` returns 200.

**Commit message**

```
sprint-9(metrics): unify collector + HTTP endpoints for health and Prometheus scraping
```

---

## Sprint 10 ‚Äî Intent routing & skills completion

**Goal:** Make routing real: local skills, LLM (Flowise), automation (n8n).

**Tasks**

* `routing/intent_router.py`:

  * Simple classifier (rules or lightweight model).
  * Dispatch matrix: skill ‚Üí local handler; knowledge ‚Üí Flowise (if env set); automation ‚Üí n8n.
* `skills/` loader with clean extension points.

**Acceptance**

* With env configured, intents reach Flowise/n8n; without, local paths still function.

**Commit message**

```
sprint-10(routing): functional intent router with skills plugin loader and optional Flowise/n8n paths
```

---

## Sprint 11 ‚Äî Error handling & client resilience

**Goal:** Harden server and client interaction.

**Tasks**

* Server: catch/send structured errors, close sequences cleanly on failure, backpressure logs.
* Desktop: add reconnect with backoff; health probe on startup; error banner on auth/connect failures.

**Acceptance**

* Kill/restart server ‚Üí client reconnects automatically; no orphaned sequences.

**Commit message**

```
sprint-11(hardening): structured errors, graceful sequence closes, desktop reconnect with backoff
```

---

## Sprint 12 ‚Äî Model discovery & validation

**Goal:** Fewer surprises at runtime.

**Tasks**

* Voice alias map (e.g., `de-thorsten-low` ‚Üí `de_DE-thorsten-low`) and model scanning at startup.
* CLI `python -m ws_server.cli --validate-models` prints missing/linked models.

**Acceptance**

* Startup logs list available voices; missing assets produce actionable warnings.

**Commit message**

```
sprint-12(models): voice aliasing, asset discovery, and validation CLI
```

---

## Sprint 13 ‚Äî Configurable LLM prosody prompt

**Goal:** Consistently speakable output.

**Tasks**

* Add system prompt promoting short, punctuated sentences (‚â§500 chars).
* Server‚Äëside hard cap post‚Äëgen via `_limit_and_chunk`.

**Acceptance**

* Long LLM answers are neatly chunked and read well; no Markdown/list formatting.

**Commit message**

```
sprint-13(llm-prosody): add speakable system prompt and hard-cap chunking
```

---

## Sprint 14 ‚Äî CI pipeline & ‚Äúno duplicates‚Äù gate

**Goal:** Keep debt from creeping back.

**Tasks**

* GitHub Actions (or local script): `ruff`, `pytest -q`, `scripts/repo_hygiene.py --check`.
* Fail CI if hygiene fails or coverage drops below baseline (set minimal threshold initially).

**Acceptance**

* CI green locally; hygiene fails on re‚Äëintroduced backups/dupes.

**Commit message**

```
sprint-14(ci): add lint/tests/hygiene gates; fail on duplicates or deprecated paths
```

---

## Sprint 15 ‚Äî Desktop playback sequencer polish

**Goal:** Smooth multi‚Äëchunk audio UX.

**Tasks**

* Queue by `sequence_id`, prebuffer next chunk, crossfade 80‚Äì120 ms.
* Toggles: fast‚Äëstart (Piper), chunk playback, crossfade duration.

**Acceptance**

* No audible gaps between intro and main; UI shows chunk progress.

**Commit message**

```
sprint-15(desktop): queued playback with prebuffer and crossfade; UX toggles
```

---

## Sprint 16 ‚Äî Docs & release notes

**Goal:** Ship a coherent story.

**Tasks**

* Update `docs/UNIFIED_SERVER.md`, `docs/STAGED_TTS.md`.
* Write `UPGRADE_NOTES.md` for the unified entrypoint.
* Summarize deprecations in `DEPRECATIONS.md`.

**Acceptance**

* Fresh checkout can run backend + desktop app using only documented steps.

**Commit message**

```
sprint-16(docs): unify docs, upgrade notes, and final deprecations list
```

---

## Test suite expectations (add or fix as you go)

* **Protocol/transport**

  * JSON hello + legacy `type:"hello"` accepted; `op:"ready"` returned.
  * Binary frames parsed and routed; JSON base64 fallback still works.
* **TTS/STT**

  * `_limit_and_chunk` unit tests: boundaries (120/180/500).
  * Staged TTS emits `tts_chunk` then `tts_sequence_end` even on Zonos timeout.
  * Engine fallback when model missing.
* **Routing**

  * Skill ‚Üí local handler; knowledge ‚Üí Flowise (mocked); automation ‚Üí n8n (mocked).
* **Metrics/health**

  * `/health` 200; `/metrics` exports new counters/histograms.

---

## Done criteria (project level)

* One server entrypoint, **zero runtime imports** from legacy paths.
* No duplicates or backup files on the import path; hygiene script clean.
* Lower perceived TTFB via Piper intro; stable Zonos follow‚Äëup.
* In‚Äëmemory STT with measurable latency improvement.
* Desktop app bound to unified server with reconnect.
* Clear docs; safe upgrade path; tests green.

---

**Final note to Codex:**
Operate only on files in this repository. Don‚Äôt fetch or invent external code. Keep each sprint self‚Äëcontained, reversible, and covered by tests and docs.

# Analyse der Projektstruktur und Refaktorierungsplan Sprachassistent
Identifizierte Probleme und technische Schulden

Parallele Implementierungen & Duplikate: In der Codebasis existieren mehrere parallele Versionen gleicher Funktionalit√§t. Besonders auff√§llig ist dies beim WebSocket-Server ‚Äì es gab unterschiedliche Varianten (z.B. ws-server.py, ‚Äûenhanced‚Äú Versionen) mit redundanten Funktionen
GitHub
. √Ñhnliches gilt f√ºr die Frontend-GUI, die teils doppelt in gui/ und voice-assistant-apps/shared/ gepflegt wurde
GitHub
. Diese Duplikate machen den Code un√ºbersichtlich und f√ºhren zu Inkonsistenzen.

Ungeordnete Projektstruktur: Das Projekt wirkt chaotisch strukturiert. Viele alte Dateien liegen in archive/ und teils existieren noch Verweise darauf. Beispielsweise wird im aktuellen Server-Code Legacy-Code dynamisch geladen
GitHub
, um √§ltere Implementierungen weiter zu unterst√ºtzen. In Deprecations ist eine lange Liste veralteter Module aufgef√ºhrt, die durch neue ersetzt wurden
GitHub
 ‚Äì dies zeigt, dass veralteter Code zwar markiert, aber noch nicht konsequent entfernt wurde. Insgesamt sind Funktionen nicht klar modularisiert, sondern verteilt und teilweise mehrfach vorhanden.

Monolithischer Code und mangelnde Modularisierung: Wesentliche Kernfunktionen liegen in sehr gro√üen Dateien statt in getrennten Modulen. So enth√§lt die zentrale WebSocket-Server-Datei (aktuell legacy_ws_server.py im Kompatibilit√§tsmodus) zahlreiche Klassen und Funktionen (STT-Streaming, Intent-Handling, TTS-Steuerung, etc.) in einem einzigen File
GitHub
. Dies erschwert das Verst√§ndnis und die Wartung. Wichtige Komponenten wie Audio-Streaming, Intent-Routing oder Authentifizierung sind nicht als separate Module gekapselt, sondern im Mischmasch implementiert.

Technische Schulden in Ein-/Ausgabe & Performance: Einige Implementierungsdetails sind suboptimal gel√∂st und f√ºhren zu vermeidbarer Latenz. Beispielsweise schreibt der STT-Prozess momentan Audiodaten tempor√§r auf die Festplatte (WAV-Datei), um sie dann wieder zu laden
GitHub
 ‚Äì anstatt direkt in-memory mit NumPy/PyDub zu arbeiten. Auch wurde Piper-TTS fr√ºher √ºber einen separaten Subprozess aufgerufen
GitHub
, was Overhead erzeugt. Obwohl inzwischen ein TTSManager existiert, m√ºssen solche Altlasten (Datei-I/O, externe Prozesse) identifiziert und eliminiert werden, um die Latenz zu senken.

Unvollst√§ndige Feature-Integration: Einige Funktionen sind erst rudiment√§r oder nur teilweise umgesetzt. So ist die Intent-Routing-Logik derzeit simpel (erkennt z.B. nur Wetter oder Begr√º√üung) und leitet komplexe Anfragen noch nicht wirklich an Flowise oder n8n weiter
GitHub
, obwohl die Doku dies vorsieht. Auch das lokale Skill-System und ein Intent-Klassifizierer sind zwar angedacht
GitHub
, aber im Code nur als Platzhalter (z.B. Dummy-Klassen in IntentClassifier und leere skills.load_all_skills R√ºckgaben
GitHub
GitHub
). Diese teils unfertigen Features mindern derzeit die Funktionalit√§t und Qualit√§t der Anwendung.

Inkonsistente Benennung und Legacy-Konfusion: Durch die vielen Entwicklungsiterationen gibt es historische Namensreste wie ‚Äúv1‚Äù, ‚Äúv2‚Äù, ‚Äúenhanced‚Äù, etc. innerhalb des Projekts. Dies kann neue Entwickler verwirren. In den Guidelines wird ausdr√ºcklich empfohlen, solche Suffixe zu vermeiden und obsoleten Code klar zu archivieren
GitHub
. Momentan finden sich jedoch z.B. Verweise auf ‚Äûbinary v2‚Äú parallel zu JSON v1 im Protokoll
GitHub
 und Dateien wie ws_server_old.py, ws_server_enhanced.py im Archiv. Diese Mischung erschwert die Wartung und birgt Risiko, versehentlich alte Komponenten zu verwenden.

Geringe Testabdeckung und potenzielle Stabilit√§tsprobleme: Automatisierte Tests sind kaum vorhanden; nur vereinzelte manuelle Testskripte existieren. Fehlendes Testing erschwert Refaktorierungen, da nicht sofort ersichtlich ist, ob bestehende Features intakt bleiben
GitHub
. Zudem gibt es verbesserungsw√ºrdige Fehlerbehandlung ‚Äì etwa sollte der WebSocket-Server robustere Retry-Mechanismen und Client-Reconnects unterst√ºtzen
GitHub
. Ohne solche Ma√ünahmen kann es bei Netzwerkfehlern zu h√§ngenden Verbindungen oder Abst√ºrzen kommen, was die Zuverl√§ssigkeit beeintr√§chtigt.

Plan zur Behebung der Probleme (Refactoring)

Duplikate konsolidieren: Zusammenf√ºhrung paralleler Implementierungen zu einer einzigen Codebasis. Insbesondere wird der WebSocket-Server vollst√§ndig vereinheitlicht, indem alle Funktionen aus den historischen Varianten in den aktuellen Server √ºbernommen werden
GitHub
. Veraltete Dateien (z.B. ws-server-old.py, ws-server-enhanced.py) k√∂nnen dann gel√∂scht oder endg√ºltig ins Archiv verschoben werden, sodass kein produktiver Code mehr darauf zeigt. Ebenso im Frontend: Die doppelte GUI-Codebasis wird aufgel√∂st, indem man die neue Web-GUI (aktuell z.B. gui/index.html als modernere Variante) und die shared Komponenten verschmilzt und nur eine Quelle f√ºr alle Clients pflegt
GitHub
.

Projektstruktur aufr√§umen und vereinheitlichen: Einf√ºhrung einer klaren Ordner- und Modulstruktur, um Chaos zu beseitigen. Der Backend-Code sollte in einen konsistenten Namespace (z.B. backend/ oder direkt ws_server/) √ºberf√ºhrt werden, anstatt verteilt in backend, ws_server, archive und root-Skripte. Eine m√∂gliche Zielstruktur ist in der Dokumentation skizziert ‚Äì mit Unterordnern f√ºr Audio, Routing, Auth, Config etc.
GitHub
GitHub
. Konkret hei√üt das: Audio-Verarbeitung (Streaming, VAD, STT/TTS-Engine) in ein eigenes Paket, Intent-Routing/Skills in ein eigenes Modul, Authentifizierung/Token-Handhabung separat, und einen klaren zentralen Einstiegspunkt f√ºr den Server. Dieses Reorganisieren beseitigt viele technische Schulden, da zusammengeh√∂rige Funktionen geb√ºndelt und unn√∂tige Verschachtelungen entfernt werden.

Obsoleten Code entfernen oder isolieren: Alle nicht mehr ben√∂tigten Altlasten sollten identifiziert werden. Code, der durch neue Implementierungen √ºberfl√ºssig wurde, wird gel√∂scht oder zumindest in ein klar gekennzeichnetes archive/ verschoben (und aus dem Build/Import-Pfad verbannt). Beispielsweise k√∂nnen alte Skills-/Intent-Klassifier-Dateien aus fr√ºheren Experimenten, die derzeit nur Dummy-Funktionen liefern, entfernt werden, sobald ein neues Skillsystem greift. Dadurch verringert sich die Verwirrung und der aktive Codeumfang. Wichtig: Dabei alle bestehenden Features erhalten, au√üer sie werden durch eine neue Implementierung ersetzt (d.h. keine funktionalen Einschnitte f√ºr den Nutzer). Die Deprecation-Tabelle
GitHub
 dient hier als Leitfaden, was schon ersetzt wurde ‚Äì diese Stellen m√ºssen nachgezogen und Altcode entsorgt werden.

Modularisierung und Aufteilung gro√üer Komponenten: Der monolithische WebSocket-Server-Code wird in logische Module zerlegt. Z.B. eine Klasse AudioStreamManager und der VAD kommen in audio/streaming.py, die STT-Logik (AsyncSTTEngine) in audio/stt_engine.py, die TTS-Logik in audio/tts_engine.py usw.
GitHub
. Die Intent-Routing-Entscheidung (_generate_response) wandert in eine eigene Komponente, etwa routing/intent_router.py, welche je nach Intent entscheidet, ob ein lokaler Skill, der LLM-Agent (Flowise) oder ein n8n-Workflow aufgerufen wird. Auch eine Vorbereitung f√ºr Auth (z.B. auth/token_utils.py und perspektivisch auth/rate_limiter.py) ist sinnvoll, selbst wenn Auth jetzt noch einfach ist
GitHub
. Diese Trennung verbessert die Lesbarkeit enorm und erlaubt es, einzelne Teile unabh√§ngig weiterzuentwickeln oder auszutauschen, ohne die ganze Datei anfassen zu m√ºssen
GitHub
.

Konfiguration und Naming konsistent gestalten: Einf√ºhrung einer zentralen Konfigurationsverwaltung (z.B. mit einer config/settings.py oder Nutzung von .env via Pydantic Settings) stellt sicher, dass alle Module die gleichen Einstellungen nutzen
GitHub
. Dabei alle alten ENV-Variablen pr√ºfen und vereinheitlichen (z.B. nur noch WS_PORT statt verstreuter Port-Konstanten). Zudem die Benennung vereinheitlichen: keine verwirrenden Suffixe wie v2 oder enhanced mehr im aktiven Code. Stattdessen klare Klassen-/Dateinamen, die den Zweck beschreiben (z.B. VoiceServer als Haupt-Serverklasse, IntentRouter, TTSManager etc.). Dieser Schritt reduziert kognitive Last und folgt den eigenen Guidelines
GitHub
.

Leistungshungrige Teile optimieren: Behebung der identifizierten ineffizienten Stellen im Code. Insbesondere muss die STT-Verarbeitung komplett auf In-Memory umgestellt werden ‚Äì das hei√üt, Audiobuffer direkt als NumPy-Array an Whisper weitergeben, ohne tempor√§re Dateien
GitHub
. Die Implementierung von AsyncSTTEngine._transcribe_sync kann dahingehend angepasst werden, wie es im Architekturvorschlag bereits angedacht ist (Konvertierung des Byte-Streams zu NumPy und WhisperModel direkt aufrufen)
GitHub
GitHub
. Ebenso sollte Piper nicht mehr via externem piper-CLI aufgerufen werden, sondern √ºber das Python-Modul (z.B. piper-tts-python) innerhalb des TTSManagers laufen
GitHub
. Dadurch spart man Prozessstartzeit und kann Geschwindigkeit/Stimme direkt als Parameter √ºbergeben. Insgesamt sorgen diese Optimierungen f√ºr sp√ºrbar geringere Latenz und CPU-Overhead.

Feature-Funktionalit√§t fertigstellen: Die begonnenen, aber unvollendeten Features werden zu Ende implementiert. Konkret: Intent-Routing ‚Äì Die Umgebungsvariablen FLOWISE_URL/FLOWISE_ID und N8N_URL sollten tats√§chlich genutzt werden, um bei bestimmten erkannten Intents HTTP-Aufrufe an Flowise (LLM-Agent) bzw. n8n zu machen
GitHub
. Hierf√ºr wird im IntentRouter hinterlegt, welche Keywords/Intents komplexe KI-Fragen darstellen (z.B. ‚Äûopenai_question‚Äú) vs. lokale Befehle, und entsprechend die Request an den externen Dienst abgesetzt. Lokale Skills ‚Äì Entwicklung eines einfachen Plug-in-Systems, das Skills (z.B. Python-Module in einem skills/ Ordner) l√§dt und deren Funktionen bei bestimmten Intents ausf√ºhrt. So k√∂nnen Offline-Funktionen (Smart-Home-Steuerung, Medienwiedergabe etc.) implementiert werden, die ohne Cloud auskommen
GitHub
. Intent-Classifier ‚Äì Integration eines kleinen NLP-Modells oder regelbasierten Systems, das eingehende Texte grob einer Intent-Kategorie zuordnet, um das Routing zu unterst√ºtzen (z.B. Konfidenzwerte f√ºr ‚Äûist wahrscheinlich eine Wissensfrage‚Äú). Diese Komponenten stellen sicher, dass alle im Konzept beschriebenen Routen (einfacher Befehl vs. komplexe Frage vs. Automation) wirklich funktionieren und nicht nur als Platzhalter im Code stehen.

Verbesserte Fehlerbehandlung und Tests einf√ºhren: Um die Stabilit√§t zu erh√∂hen, wird der WebSocket-Server mit robustem Error-Handling ausgestattet. Beispielsweise kann in der Empfangsschleife von handle_websocket ein Retry-Mechanismus implementiert werden, der bei tempor√§ren Netzwerkproblemen einen erneuten Sendeversuch unternimmt
GitHub
. Auch sollte auf Client-Seite ein automatischer Reconnect (mit Exponential Backoff) unterst√ºtzt werden, falls die Verbindung abrei√üt
GitHub
. Zus√§tzlich sind Unit-Tests f√ºr die Kernbereiche unerl√§sslich: Tests f√ºr Audio-Streaming (korrekte Zerlegung und Weiterleitung von Audiopaketen), f√ºr Intent-Routing-Entscheidungen (z.B. dass ‚ÄûWetter‚Äú den richtigen Pfad nimmt), f√ºr den TTS-Manager (verschiedene Engines liefern Erfolg) etc.
GitHub
. Eine kontinuierliche Integration mit diesen Tests stellt zuk√ºnftig sicher, dass Refaktorierungen keine alten Features brechen. Ebenso sollten Performance- und Speichertests durchgef√ºhrt werden, um Memory Leaks oder Latenz-Einbr√ºche fr√ºh zu erkennen.

Entwicklungsplan f√ºr zuk√ºnftige Erweiterungen und Optimierungen

Nach der Bereinigung des bestehenden Codes soll das Sprachassistent-Projekt mit Fokus auf geringer Latenz, hoher Sprachqualit√§t, Robustheit und neuen Features ausgebaut werden. Im Folgenden die Schwerpunkte der Weiterentwicklung:

Latenzoptimierung: Die Antwortzeit des Systems soll weiter verk√ºrzt werden, sodass Sprachinteraktion in Echtzeit m√∂glich ist. Geplante Ma√ünahmen umfassen asynchrone Audioverarbeitung und Streaming in kleineren H√§ppchen. Beispielsweise kann die WebSocket-√úbertragung auf kleinere Audio-Chunks (z.B. 512‚Äì1024 Bytes) in h√∂herer Frequenz umgestellt werden und schon w√§hrend der Aufnahme verarbeitet werden
GitHub
GitHub
. Ein zweistufiges TTS-Verfahren (Staged TTS) ist bereits prototypisch vorhanden, bei dem ein kurzer Piper-‚ÄûIntro‚Äú-Satz sofort abgespielt wird, w√§hrend parallel die hochwertigere Zonos-Stimme l√§ngere Passagen generiert
GitHub
. Dieses Konzept soll weiter verfeinert werden ‚Äì z.B. durch dynamisches Chunking langer Antworten und Crossfades beim √úbergang der Stimmen, um Wartezeiten kaum sp√ºrbar zu machen. Auch auf STT-Seite k√∂nnte eine Streaming-Transkription erwogen werden, bei der laufende Audioeingaben fortlaufend zu Text verarbeitet werden (Whisper unterst√ºtzt z.B. auch segmentweises Transkribieren), sodass die Antwortgenerierung fr√ºher starten kann. Zudem wird gepr√ºft, ob Hardware-Beschleunigung besser genutzt werden kann: Auf einem Desktop/Server k√∂nnte man gr√∂√üere Whisper-Modelle auf der GPU laufen lassen, w√§hrend auf dem Pi kleinere Modelle f√ºr schnellere Ergebnisse genutzt werden ‚Äì ggf. mit automatischem Model-Switch je nach L√§nge/Komplexit√§t der Anfrage. All diese Optimierungen zielen darauf ab, die Systemlatenz von der Spracherkennung bis zur Ausgabe unter realen Bedingungen so gering wie m√∂glich zu halten (idealerweise deutlich unter 1 Sekunde f√ºr kurze Anfragen).

Steigerung der Sprachqualit√§t: Die Nat√ºrlichkeit und Verst√§ndlichkeit der Sprachausgabe soll weiter erh√∂ht werden. Hier steht TTS-Qualit√§t im Vordergrund. Zun√§chst werden die vorhandenen Engines (Piper, Kokoro, Zonos) optimal konfiguriert: Nutzung hochqualitativer Modelle (z.B. gr√∂√üere Voice-Modelle f√ºr Zonos, feinjustierte deutsche Stimmen f√ºr Piper) und automatische Sprachauswahl je nach Eingabesprache
GitHub
. Geplant ist auch eine automatische Stimmoptimierung ‚Äì das System k√∂nnte z.B. die TTS-Parameter wie Sprechgeschwindigkeit oder Tonh√∂he kontextabh√§ngig anpassen (schneller bei langen Erkl√§rungen, klarer bei lauter Umgebung). ‚ÄûAutomatic voice tuning‚Äú bedeutet auch, das TTS-Ausgabeprofil an den Nutzer anzupassen: eventuell mittels Equalizer oder Filter, um in verschiedenen R√§umen gut verst√§ndlich zu sein, oder sogar eine personalisierte Stimme zu erm√∂glichen. Auf STT-Seite wird die Erkennungsqualit√§t gesteigert, indem z.B. Rauschentfernung und VAD verbessert werden. Ein automatisches Mikrofon-Tuning kann hinzu kommen ‚Äì etwa Kalibrierung der Eingabelautst√§rke und Empfindlichkeit (AGC), damit unterschiedlich laute Sprecher gleich gut erkannt werden. Ebenso denkbar ist der Einsatz von Sprachmodell-Nachbearbeitung, um erkannte Texte zu verbessern (z.B. automatisches Hinzuf√ºgen von Satzzeichen oder Korrektur von bekannten Erkennungsfehlern durch ein kleines NLP-Modul). Ziel all dieser Ma√ünahmen ist ein ultra-realistische Sprachausgabe und eine sehr zuverl√§ssige Erkennung, sodass der Assistent so nat√ºrlich wie m√∂glich wirkt.

System-H√§rtung und Skalierbarkeit: Im produktiven Einsatz muss das System robust und sicher laufen. Daher werden zus√§tzliche Hardening-Schritte unternommen. Geplant ist die Einf√ºhrung einer Token-basierten Authentifizierung f√ºr die WebSocket-Verbindung (z.B. via JWT), um unautorisierte Zugriffe zu verhindern, besonders wenn der Server √ºber Netzwerk erreichbar ist
GitHub
. Erg√§nzend wird ein Rate Limiting implementiert, um Missbrauch (zu viele Anfragen in kurzer Zeit) zu unterbinden
GitHub
 ‚Äì wichtig sowohl f√ºr Sicherheit als auch um die Hardware (Pi) nicht zu √ºberlasten. Auch der vorhandene VPN-Ansatz (Headscale) wird integriert gepr√ºft, damit die Kommunikation zwischen den verteilten Komponenten abgesichert ist. Weiterhin steht Monitoring im Fokus: Die Metrik-Schnittstelle (Port 48232) liefert bereits Basisdaten; diese sollen in ein Monitoring-System (z.B. Prometheus/Grafana) eingespeist werden, um Latenzen, Auslastung und Fehler zentral zu √ºberwachen. F√ºr die Stabilit√§t sorgen auch intensives Testing (Stresstests, Langzeittests √ºber Tage, um Memory Leaks aufzudecken) und eine CI/CD-Pipeline, die automatisch Builds und Tests durchf√ºhrt. Schlie√ülich wird die Plattform-Unabh√§ngigkeit gepr√ºft und verbessert ‚Äì das Backend soll auf verschiedenen Hardware (Raspberry Pi, Odroid, x86-Server) gleich stabil laufen. Wo n√∂tig, werden Optimierungen je Plattform vorgenommen (z.B. alternative TTS-Modelle f√ºr ARM). All diese Schritte machen den Sprachassistenten robust gegen Ausf√§lle und einsatzbereit f√ºr den Dauerbetrieb.

Neue Features und Erweiterungen: Um das System attraktiver und hilfreicher zu machen, werden nach dem Refactoring neue Funktionen hinzugef√ºgt. Lokale Skills sollen ausgebaut werden ‚Äì etwa Module f√ºr Smart-Home-Steuerung, Musik abspielen, Terminverwaltung etc., die offline funktionieren. Gleichzeitig wird die Agent-Integration vertieft: Der LLM-Agent (√ºber Flowise) k√∂nnte mit Tools erweitert werden, z.B. einer F√§higkeit, Web-Suchen durchzuf√ºhren, um Fragen mit aktuellen Informationen zu beantworten. Dadurch kann der Assistent nicht nur vordefinierte Antworten geben, sondern auch eigenst√§ndig Informationen suchen und finden (‚Äúsearch/find new features‚Äù). Geplante ist zudem eine Verbesserung der Multi-User-Unterst√ºtzung: Der Assistent k√∂nnte Stimmen erkennen und unterschiedliche Profile pro Nutzer verwenden (z.B. verschiedene Wake-Words oder pers√∂nliche Pr√§ferenzen pro Nutzer). Die Cross-Plattform-Clients (Desktop, Mobile, Web) werden um neue Bedienungsfeatures erg√§nzt ‚Äì z.B. Push-Benachrichtigungen bei bestimmten Ereignissen, eine verbesserte Offline-Nutzung auf Mobile, oder ein Setup-Wizard in der Desktop-App, um die Ersteinrichtung zu erleichtern. Auch ein All-in-One Modus wird angestrebt: Das System soll so paketiert werden, dass eine Nutzerin es auf einem einzigen Ger√§t leicht installieren und starten kann. Im Desktop-Client wird daf√ºr der Python-Backend-Server bereits als Binary mitgeliefert
GitHub
 ‚Äì diese Integration wird weiter verfeinert, sodass der ‚ÄúServer‚Äù f√ºr Hobby-Anwender unsichtbar im Hintergrund der Desktop-App l√§uft. Sp√§ter kann dieses All-in-One-Konzept auch auf Raspberry Pi und Mobile adaptiert werden (z.B. ein Raspberry Pi Image, das Backend und Web-GUI enth√§lt, oder eine mobile App, die im lokalen Modus arbeiten kann). Schlie√ülich steht die kontinuierliche Verbesserung auf der Agenda: Das Projekt wird regelm√§√üig nach neuen sinnvollen Features durchsucht ‚Äì z.B. Unterst√ºtzung weiterer Sprachen, Integration neuer STT/TTS-Modelle aus der Open-Source-Community, oder Verbesserungen der Benutzeroberfl√§che ‚Äì und diese werden in kurzen Iterationen hinzugef√ºgt. Durch diese agile Weiterentwicklung bleibt der Sprachassistent technisch aktuell und kann mit kommerziellen L√∂sungen mithalten.

Fazit: Durch die gr√ºndliche Bereinigung der Altlasten und eine strategische Weiterentwicklung entlang der genannten Schwerpunkte wird das Sprachassistent-System deutlich wartbarer, leistungsf√§higer und funktionsreicher. Alle bestehenden Kernfunktionen bleiben erhalten (au√üer dort, wo neue Implementierungen eine alte √ºberfl√ºssig machen), sodass kein Feature-Verlust eintritt
GitHub
. Gleichzeitig legen die geplanten Refaktorierungen und Optimierungen das Fundament f√ºr beste Sprachqualit√§t, minimalste Verz√∂gerungen und eine stabile, erweiterbare Plattform, auf der in Zukunft noch viele innovative Features aufgebaut werden k√∂nnen. Mit diesem Entwicklungsplan wird aus dem momentan un√ºbersichtlichen Prototyp ein robustes, modernes All-in-One-Sprachassistenzsystem f√ºr Desktop, Raspberry Pi und mobile Ger√§te.

Sources: Die Analyse und Empfehlungen basieren auf dem aktuellen Projektcode und begleitenden Dokumenten, inkl. den Deprecation-Hinweisen
GitHub
, Code-Review-Empfehlungen
GitHub
GitHub
 und Architekturpl√§nen
GitHub
GitHub
 des Repositories. Diese belegen die vorhandenen Probleme und skizzieren bereits viele der hier vorgeschlagenen L√∂sungswege.
