# ğŸ¤– Modulares Sprachassistent-Ã–kosystem

Ein vollstÃ¤ndiges, modulares Sprachassistenten-System bestehend aus lokalem Hardware-Backend (Raspberry Pi/Odroid) und Cross-Platform Client-Apps (Desktop/Mobile) mit moderner Web-GUI, KI-Integration und Automatisierung.

![Version](https://img.shields.io/badge/version-2.1.0-blue.svg)
![Platform](https://img.shields.io/badge/platform-RaspberryPi%20%7C%20Desktop%20%7C%20Mobile-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

## ğŸ—ï¸ Systemarchitektur

Das Ã–kosystem besteht aus zwei Hauptkomponenten, die nahtlos zusammenarbeiten:

### ğŸ”§ Hardware-Backend (Lokales System)
Raspberry Pi/Odroid-basiertes Backend mit lokaler STT/TTS und KI-Integration

### ğŸ“± Client-Apps (Cross-Platform)
Electron Desktop-App und Cordova Mobile-App fÃ¼r universellen Zugriff

<details>
<summary>Klicken zum Einblenden des Architekturdiagramms</summary>
  
```mermaid
flowchart TB
  subgraph Clients
    Desktop[Desktop App]
    Mobile[Mobile App]
    WebGUI[Web GUI]
  end

  subgraph LocalBackend
    subgraph Interface
      Mic400[Mikrofon]
      GUI400[Lokale GUI]
    end

    subgraph AudioNode
      STT[STT Engine]
      TTS[TTS Engine]
      IntentRouting[Intent Routing]
      Skills[Lokale Skills]
    end

    subgraph Gateway
      Flowise[Flowise]
      n8n[n8n]
    end
  end

  subgraph CloudServer
    ServerFlowise[Flowise Full]
    ServerN8n[n8n Backend]
    ServerLLM[Lokale LLMs]
  end

  %% Connections
  Desktop -.->|WebSocket/HTTP| AudioNode
  Mobile -.->|WebSocket/HTTP| AudioNode
  WebGUI --> AudioNode

  Mic400 --> AudioNode
  GUI400 <--> AudioNode

  AudioNode -->|Complex Queries| Gateway
  Gateway -->|Heavy Tasks| CloudServer

  IntentRouting -->|Simple Tasks| Skills
  IntentRouting -->|Complex Tasks| Flowise

  %% Network
  subgraph Network
    VPN[Headscale VPN]
  end

  Clients -.-> VPN
  LocalBackend -.-> VPN
  CloudServer -.-> VPN
```
</details>


## âœ¨ Features

### ğŸ¯ Kernfunktionen
- **ğŸ¤ Lokale Spracheingabe** mit faster-whisper STT
- **ğŸ”Š Lokale Sprachausgabe** mit piper TTS  
- **ğŸ§  Intelligentes Routing** zwischen lokalen Skills und Cloud-LLMs
- **ğŸŒŠ Moderne animierte UI** mit konfigurierbaren Effekten
- **ğŸ”„ Automatisierung** mit n8n Workflows
- **ğŸ” Sichere Vernetzung** Ã¼ber Headscale VPN

### ğŸ  Hardware-Backend Features
- **Lokale STT/TTS** ohne Cloud-AbhÃ¤ngigkeit
- **Modulare Architektur** auf mehreren Raspberry Pi/Odroid
- **FlowiseAI Integration** fÃ¼r LLM-Agent-Routing
- **n8n Workflows** fÃ¼r Home-Automation
- **Intent-basiertes Routing** (lokal vs. remote)
- **Wakeword-Erkennung** mit RaspOVOS

### ğŸ“± Client-App Features

#### ğŸ–¥ï¸ Desktop (Electron)
- **Native MenÃ¼s** und Keyboard-Shortcuts
- **System Tray Integration** fÃ¼r Background-Betrieb
- **Multi-Platform** (Windows, macOS, Linux)
- **Auto-Updates** mit electron-updater
- **Drag & Drop** Support

#### ğŸ“± Mobile (Android/Cordova)
- **Touch-optimierte UI** mit Haptic Feedback
- **Background-Mode** fÃ¼r kontinuierliche Nutzung
- **Native Permissions** Management
- **Push-Benachrichtigungen**
- **PWA-Features** mit Service Worker

## ğŸ›  Technologie-Stack

### Hardware-Backend
- ğŸ¤ **STT**: [Faster-Whisper](https://github.com/guillaumekln/faster-whisper) â€“ lokale Speech-to-Text
- ğŸ”Š **TTS**: [Piper TTS](https://github.com/rhasspy/piper) â€“ Text-to-Speech auf ARM
- ğŸ—£ **Voice OS**: [RaspOVOS](https://openvoiceos.github.io/raspOVOS/) â€“ Wakeword-Erkennung
- ğŸ§  **LLM-Routing**: [FlowiseAI](https://github.com/FlowiseAI/Flowise) â€“ No-Code Agent-Flows
- ğŸ” **Automation**: [n8n](https://n8n.io/) â€“ Workflow-Automatisierung
- ğŸ” **Networking**: [Headscale](https://github.com/juanfont/headscale) â€“ sicheres privates VPN

### Client-Apps
| Komponente | Desktop | Mobile | Web |
|------------|---------|--------|-----|
| **Framework** | Electron 28+ | Cordova 12+ | Modern Web APIs |
| **UI** | HTML5/CSS3/JS | HTML5/CSS3/JS | Responsive Design |
| **Audio** | Web Audio API | Cordova Media | MediaRecorder API |
| **Notifications** | Native | Cordova Plugins | Web Notifications |
| **Storage** | Electron Store | LocalStorage | IndexedDB |

## ğŸ“ Projektstruktur

```
Sprachassistent/
â”œâ”€â”€ ğŸ  Hardware-Backend (Raspberry Pi System)
â”‚   â”œâ”€â”€ config/                  # GerÃ¤t-spezifische Konfigurationen
â”‚   â”‚   â”œâ”€â”€ raspi4/             # STT/TTS Node Konfiguration
â”‚   â”‚   â”œâ”€â”€ raspi400/           # GUI Interface Konfiguration  
â”‚   â”‚   â””â”€â”€ odroid/             # Gateway Konfiguration
â”‚   â”œâ”€â”€ scripts/                # Setup & Wartungs-Skripte
â”‚   â”‚   â”œâ”€â”€ setup-headscale.sh
â”‚   â”‚   â”œâ”€â”€ install-piper.sh
â”‚   â”‚   â”œâ”€â”€ start-stt.sh
â”‚   â”‚   â””â”€â”€ start-tts.sh
â”‚   â”œâ”€â”€ gui/                    # Lokale Web-GUI
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ app.js
â”‚   â”‚   â””â”€â”€ styles.css
â”‚   â””â”€â”€ docs/                   # Hardware-System Dokumentation
â”‚
â”œâ”€â”€ ğŸ“± Client-Apps (Cross-Platform)
â”‚   â””â”€â”€ voice-assistant-apps/
â”‚       â”œâ”€â”€ desktop/            # Electron Desktop App
â”‚       â”‚   â”œâ”€â”€ src/           # Haupt-App Code
â”‚       â”‚   â”œâ”€â”€ package.json
â”‚       â”‚   â””â”€â”€ build/         # Build-Output
â”‚       â”œâ”€â”€ mobile/            # Cordova Mobile App
â”‚       â”‚   â”œâ”€â”€ www/           # Web-Assets
â”‚       â”‚   â”œâ”€â”€ config.xml     # Cordova Konfiguration  
â”‚       â”‚   â”œâ”€â”€ hooks/         # Build-Hooks
â”‚       â”‚   â””â”€â”€ platforms/     # Android/iOS
â”‚       â”œâ”€â”€ shared/            # Gemeinsame Komponenten
â”‚       â”‚   â”œâ”€â”€ app.js         # Core-Logik
â”‚       â”‚   â””â”€â”€ index.html     # Basis-Template
â”‚       â””â”€â”€ build_all.sh       # Cross-Platform Build-Script
â”‚
â””â”€â”€ ğŸ“š Dokumentation & Setup
    â”œâ”€â”€ README.md              # Diese Datei
    â”œâ”€â”€ CONTRIBUTING.md        # Beitragen-Guidelines
    â”œâ”€â”€ LICENSE               # MIT Lizenz
    â””â”€â”€ env.example          # Umgebungsvariablen-Template
```

## ğŸš€ Quick Start

### Voraussetzungen
```bash
# FÃ¼r Hardware-Backend
- Raspberry Pi 4 (STT/TTS Node)
- Raspberry Pi 400 (GUI Interface) 
- Odroid N2 oder Ã¤hnlich (Gateway)
- Optional: Server fÃ¼r schwere LLM-Tasks

# FÃ¼r Client-Apps
- Node.js 18+ & NPM 8+
- Android Studio (fÃ¼r Mobile)
- Git
```

### 1. ğŸ  Hardware-Backend Setup

#### Raspberry Pi 4 (STT/TTS Node)
```bash
# STT Engine installieren
git clone https://github.com/guillaumekln/faster-whisper
cd faster-whisper && pip install .

# TTS Engine installieren  
sudo apt install piper

# Projekt klonen und konfigurieren
git clone https://github.com/161sam/Sprachassistent.git
cd Sprachassistent
cp env.example .env
# .env bearbeiten mit deinen Einstellungen

# STT/TTS Services starten
./scripts/start-stt.sh
./scripts/start-tts.sh
```

#### Raspberry Pi 400 (GUI Interface)
```bash
cd Sprachassistent/gui
python -m http.server 8080
# GUI unter http://localhost:8080 verfÃ¼gbar
```

#### Odroid N2 (Gateway)
```bash
# Flowise installieren
git clone https://github.com/FlowiseAI/Flowise
cd Flowise && npm install && npm run build

# n8n installieren  
docker run -it --rm -p 5678:5678 n8nio/n8n

# Services starten
npm start  # Flowise
# n8n lÃ¤uft bereits im Docker Container
```

#### Headscale Setup (Odroid & Clients)
```bash
# Auf jedem GerÃ¤t ausfÃ¼hren
./scripts/setup-headscale.sh
sudo headscale up --hostname raspi4-stt    # entsprechend anpassen
sudo headscale up --hostname raspi400-gui
sudo headscale up --hostname odroid-gateway
```

### 2. ğŸ“± Client-Apps Setup

```bash
cd voice-assistant-apps

# Desktop App
cd desktop
npm install
npm run dev  # Development

# Mobile App  
cd ../mobile
npm install
npm install -g cordova
cordova platform add android
cordova run android

# Alle Apps bauen
../build_all.sh all release
```

## âš™ï¸ Konfiguration

### Intent-Routing konfigurieren

Das System routet Anfragen intelligent zwischen lokalen Skills und Remote-Services:

```json
// config/raspi4/routing-config.json
{
  "intents": {
    "weather": {
      "target": "n8n-workflow",
      "endpoint": "odroid-n2.headscale:5678/webhook/weather"
    },
    "ai_question": {
      "target": "flowise-agent", 
      "endpoint": "odroid-n2.headscale:3000/api/v1/prediction/agent-id"
    },
    "smart_home": {
      "target": "local-skill",
      "handler": "home_automation"
    },
    "calculation": {
      "target": "local-skill",
      "handler": "math_calculator"
    }
  }
}
```

### Client-App Verbindung konfigurieren

```javascript
// voice-assistant-apps/shared/app.js
const config = {
  // Hauptverbindung zum Raspberry Pi STT/TTS Node
  websocket: {
    url: 'ws://raspi4-stt.headscale:8123',
    fallback: 'ws://192.168.1.100:8123'
  },
  
  // Direkte Verbindung zu Flowise/n8n (optional)
  flowise: {
    url: 'http://odroid-gateway.headscale:3000'
  },
  
  n8n: {
    url: 'http://odroid-gateway.headscale:5678'  
  }
};
```

## ğŸ§  Intent-Routing Logik

| Intent-Beispiel | Ziel | Handler |
|----------------|------|---------|
| "Wie ist das Wetter?" | n8n Workflow | Wetter-API Call |
| "Was ist KÃ¼nstliche Intelligenz?" | Flowise Agent | LLM (GPT/Claude/Llama) |
| "Mach das Licht an" | Local Skill | Home Assistant Integration |
| "Rechne 25 mal 17" | Local Skill | Math Calculator |
| "Spiele Musik ab" | Local Skill | MPD/Spotify Control |
| "Schreibe eine E-Mail" | Flowise Agent | LLM + SMTP Workflow |

## ğŸ–¥ï¸ Usage Examples

### Hardware-Backend (Direct)
```bash
# Direkt mit Raspberry Pi GUI interagieren
# Web-Interface: http://raspi400-gui.headscale:8080

# Voice Command via Mikrofon
"Hey Assistant, wie ist das Wetter heute?"
# -> n8n Workflow -> OpenWeatherMap API -> TTS Response

# Text Input via GUI
"ErklÃ¤re mir Machine Learning"  
# -> Flowise Agent -> Local LLM -> Text Response
```

### Desktop App (Electron)
```bash
# Desktop App starten
cd voice-assistant-apps/desktop
npm run dev

# Features:
# - Native Desktop Integration
# - System Tray fÃ¼r Background-Betrieb  
# - Keyboard Shortcuts (Ctrl+Enter fÃ¼r Voice)
# - Auto-Updates
# - Multi-Monitor Support
```

### Mobile App (Android)
```bash
# Mobile App installieren
cd voice-assistant-apps/mobile
cordova run android --device

# Features:
# - Touch-optimierte UI
# - Haptic Feedback
# - Background-Mode
# - Push Notifications
# - Offline-FÃ¤higkeiten
```

## ğŸ§ª Testing & Debugging

### Hardware-Backend Testing
```bash
# STT Service testen
curl -X POST http://raspi4-stt.headscale:8123/stt \
  -H "Content-Type: application/json" \
  -d '{"audio": "base64_audio_data"}'

# TTS Service testen  
curl -X POST http://raspi4-stt.headscale:8123/tts \
  -H "Content-Type: application/json" \
  -d '{"text": "Hallo Welt", "voice": "de-thorsten"}'

# Intent Routing testen
curl -X POST http://raspi4-stt.headscale:8123/query \
  -H "Content-Type: application/json" \
  -d '{"text": "Wie ist das Wetter?", "session": "test"}'
```

### Client-Apps Testing
```bash
# Desktop App Tests
cd voice-assistant-apps/desktop
npm test
npm run e2e

# Mobile App Tests
cd voice-assistant-apps/mobile  
cordova run android --debug
# Chrome DevTools: chrome://inspect -> Remote Targets
```

## ğŸ“¦ Deployment & Distribution

### Hardware-Backend Deployment
```bash
# Raspberry Pi Image erstellen
# 1. SD-Karte mit Raspberry Pi OS flashen
# 2. Setup-Skripte ausfÃ¼hren
./scripts/setup-complete-system.sh

# Docker Deployment (optional)
docker-compose -f docker-compose.hardware.yml up -d
```

### Client-Apps Distribution

#### Desktop Apps
```bash
cd voice-assistant-apps
./build_all.sh desktop release

# Outputs:
# - KI-Sprachassistent-2.1.0.exe (Windows)
# - KI-Sprachassistent-2.1.0.dmg (macOS)  
# - KI-Sprachassistent-2.1.0.AppImage (Linux)
```

#### Mobile Apps
```bash
./build_all.sh mobile release

# Outputs:
# - app-release.apk (Android)
# - Signed fÃ¼r Google Play Store
```

## ğŸ”§ Entwicklung & Anpassung

### Neue Local Skills hinzufÃ¼gen
```python
# skills/weather_skill.py
class WeatherSkill:
    def handle_intent(self, intent_data):
        location = intent_data.get('location', 'hier')
        weather = self.get_weather(location)
        return f"Das Wetter in {location} ist {weather}"
    
    def get_weather(self, location):
        # API Call zu OpenWeatherMap
        pass
```

### Flowise Agent erweitern
```json
// flowise-flows/assistant-agent.json
{
  "nodes": [
    {
      "id": "llm-node",
      "type": "ChatOpenAI",
      "data": {
        "model": "gpt-4",
        "temperature": 0.7
      }
    },
    {
      "id": "memory-node", 
      "type": "ConversationSummaryMemory"
    }
  ]
}
```

### n8n Workflow erstellen
```json
// n8n-workflows/smart-home-control.json
{
  "name": "Smart Home Control",
  "nodes": [
    {
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "parameters": {
        "path": "smart-home"
      }
    },
    {
      "name": "Home Assistant",
      "type": "n8n-nodes-base.homeAssistant" 
    }
  ]
}
```

## ğŸ¤ Contributing

Wir freuen uns Ã¼ber BeitrÃ¤ge zu beiden Teilen des Systems! Bitte lesen Sie unsere [Contributing Guidelines](CONTRIBUTING.md).

### Entwicklungsbereiche
- **ğŸ  Hardware-Backend:** Python Skills, STT/TTS Optimierung, Routing-Logik
- **ğŸ“± Client-Apps:** UI/UX Verbesserungen, neue Features, Cross-Platform Support  
- **ğŸ§  KI-Integration:** Flowise Flows, n8n Workflows, LLM Optimierung
- **ğŸ“š Dokumentation:** Tutorials, Setup-Guides, Architecture Docs

### Development Workflow
1. **Fork** das Repository
2. **Branch** erstellen (`git checkout -b feature/amazing-feature`)
3. **Commit** Ã„nderungen (`git commit -m 'Add amazing feature'`)
4. **Test** auf verschiedenen Komponenten
5. **Pull Request** Ã¶ffnen

## ğŸ› Troubleshooting

### Hardware-Backend Probleme
```bash
# STT Service funktioniert nicht
sudo systemctl status faster-whisper
journalctl -u faster-whisper -f

# TTS Audio-Ausgabe fehlt
alsamixer  # Audio-Level prÃ¼fen
aplay /usr/share/sounds/alsa/Front_Left.wav

# Headscale Verbindung
headscale ping raspi4-stt
headscale status
```

### Client-App Probleme
```bash
# Desktop Build-Fehler
cd voice-assistant-apps/desktop
rm -rf node_modules package-lock.json
npm install

# Mobile Build-Fehler  
cd voice-assistant-apps/mobile
cordova clean android
cordova platform rm android && cordova platform add android
```

### Netzwerk & Verbindung
```bash
# WebSocket-Verbindung testen
wscat -c ws://raspi4-stt.headscale:8123

# Firewall prÃ¼fen
sudo ufw status
sudo iptables -L

# DNS Resolution  
nslookup raspi4-stt.headscale
ping raspi4-stt.headscale
```

## ğŸ“Š Roadmap

### Version 2.2.0 (Q2 2025)
- [ ] iOS Mobile App Support
- [ ] Wake Word Training Interface
- [ ] Advanced Intent Classification (ML-based)
- [ ] Multi-Language STT/TTS Support
- [ ] Home Assistant Deep Integration

### Version 2.3.0 (Q3 2025)
- [ ] Edge AI Acceleration (Coral TPU Support)
- [ ] Custom Voice Cloning with Piper
- [ ] Advanced n8n Workflow Templates
- [ ] Distributed Load Balancing
- [ ] Advanced Analytics Dashboard

### Version 3.0.0 (Q4 2025)
- [ ] Complete Architecture Redesign
- [ ] Kubernetes Orchestration Support
- [ ] Advanced Multi-Agent Systems
- [ ] Real-time Voice Conversation Mode
- [ ] Integrated Video Understanding

## ğŸ† Use Cases

### ğŸ  Smart Home Hub
- Zentrale Steuerung aller Smart Home GerÃ¤te
- Sprachbasierte Automatisierung
- Lokale Verarbeitung ohne Cloud

### ğŸ–¥ï¸ Desktop Productivity
- Meeting-Notizen per Spracheingabe
- E-Mail-Diktat und -Versand
- Kalender- und Task-Management

### ğŸ“± Mobile Assistant  
- Unterwegs-Zugriff auf Home-System
- Location-based Automations
- Offline-FunktionalitÃ¤t

### ğŸ¢ Business Integration
- CRM-Integration Ã¼ber n8n
- Workflow-Automatisierung
- Team-ProduktivitÃ¤ts-Tools

## ğŸ“„ Lizenz

Dieses Projekt ist unter der [MIT License](LICENSE) lizenziert.

## ğŸ™ Danksagungen

### Hardware-Backend
- **Faster-Whisper** Team fÃ¼r lokale STT-Engine
- **Piper TTS** Entwickler fÃ¼r ARM-optimierte TTS
- **RaspOVOS** Community fÃ¼r Wakeword-Integration
- **FlowiseAI** fÃ¼r No-Code LLM-Workflows
- **n8n** fÃ¼r offene Automatisierungsplattform
- **Headscale** fÃ¼r sichere Vernetzung

### Client-Apps  
- **Electron** Team fÃ¼r Desktop-Framework
- **Apache Cordova** fÃ¼r Mobile-Platform
- **Web Audio API** Implementierer
- **Open Source** Community

---

**ğŸŒŸ Entwickelt mit â¤ï¸ fÃ¼r die Voice Assistant & Maker Community**

**â­ Star uns auf GitHub, wenn dieses Projekt hilfreich ist!**

---

## ğŸ”— WeiterfÃ¼hrende Links

- ğŸ“š **[Hardware Setup Guide](docs/hardware-setup.md)**
- ğŸ—ï¸ **[Architecture Deep Dive](docs/architecture.md)**
- ğŸ”§ **[Development Guide](docs/development.md)**
- ğŸ¤ **[Contributing Guidelines](CONTRIBUTING.md)**
- ğŸ› **[Issues & Support](https://github.com/your-repo/issues)**
- ğŸ’¬ **[Discussions](https://github.com/your-repo/discussions)**
